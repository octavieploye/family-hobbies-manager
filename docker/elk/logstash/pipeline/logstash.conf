# ============================================================
# Logstash Pipeline: Family Hobbies Manager
# ============================================================
# Input:  TCP port 5044 (structured JSON from logstash-logback-encoder)
# Filter: JSON parse, field promotion, timestamp normalization
# Output: Elasticsearch with daily index rotation
# ============================================================

input {
  tcp {
    port => 5044
    codec => json_lines {
      charset => "UTF-8"
    }
    type => "application-log"
  }
}

filter {
  # --------------------------------------------------------
  # 1. Parse the JSON payload if not already parsed by codec
  # --------------------------------------------------------
  if [message] =~ /^\{/ {
    json {
      source => "message"
      target => "parsed"
      skip_on_invalid_json => true
    }

    if [parsed] {
      mutate {
        replace => {
          "message" => "%{[parsed][message]}"
        }
      }
    }
  }

  # --------------------------------------------------------
  # 2. Promote MDC fields to top-level for efficient queries
  # --------------------------------------------------------
  if [mdc] {
    mutate {
      rename => {
        "[mdc][traceId]"     => "traceId"
        "[mdc][userId]"      => "userId"
        "[mdc][serviceName]" => "serviceName"
        "[mdc][spanId]"      => "spanId"
        "[mdc][requestUri]"  => "requestUri"
        "[mdc][httpMethod]"  => "httpMethod"
      }
      remove_field => ["mdc"]
    }
  }

  # --------------------------------------------------------
  # 3. Normalize timestamp to ISO-8601
  # --------------------------------------------------------
  if [@timestamp] {
    date {
      match => ["@timestamp", "ISO8601"]
      target => "@timestamp"
    }
  }

  # --------------------------------------------------------
  # 4. Extract service name from logger if not in MDC
  # --------------------------------------------------------
  if ![serviceName] and [logger_name] {
    grok {
      match => {
        "logger_name" => "com\.familyhobbies\.(?<serviceName>[a-z]+service)\."
      }
      tag_on_failure => []
    }
  }

  # --------------------------------------------------------
  # 5. Add log level as keyword for aggregations
  # --------------------------------------------------------
  if [level] {
    mutate {
      add_field => { "log_level" => "%{level}" }
    }
  }

  # --------------------------------------------------------
  # 6. Parse stack trace for error logs
  # --------------------------------------------------------
  if [stack_trace] {
    mutate {
      add_field => { "has_exception" => "true" }
    }
  } else {
    mutate {
      add_field => { "has_exception" => "false" }
    }
  }

  # --------------------------------------------------------
  # 7. Clean up internal fields
  # --------------------------------------------------------
  mutate {
    remove_field => ["parsed", "host", "port", "type"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "family-hobbies-%{+YYYY.MM.dd}"
  }

  # Debug: also output to Logstash stdout (remove in production)
  stdout {
    codec => rubydebug {
      metadata => false
    }
  }
}
